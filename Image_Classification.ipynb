{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 27947,
          "databundleVersionId": 2289661,
          "sourceType": "competition"
        },
        {
          "sourceId": 2235745,
          "sourceType": "datasetVersion",
          "datasetId": 1343296
        }
      ],
      "dockerImageVersionId": 30096,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Image Classification",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dinaalshraif/Image-Classification/blob/main/Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'deep-learning-for-msc-coursework-2021:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F27947%2F2289661%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240704%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240704T074457Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Da92c8ef1aa475c7a601ae598c00b1bd390a782d7726248335f0b8a3941d00336d28cf73e6a8c57766c4f7202663a50279244b2f4b0ebffa1403fbd36e198ec80016ba91292c47050ab549b59bfee5fee24e3e26c95be9b82a51a19f32224a81b3302274100cfb4f6c674854ed616319ad00b54c08be059bbd569e5bf75347b2a071c664aa464b52d91116eb18f125ee0d8557c3c00fa607ebcb303d328808ffc818ad370530494acba72cfda02a9a1c712f714d1946b6b670006d45fdb48dfca43b87660401cbe7bf0a5837e2a7c6e1d13eeaae9807ec8e1f9782d111fe5e71dc25ab70e3ea6f05f4c9f7d2864d4c175410d10fce22e7b0be00f0cc09482a130,traincsv:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1343296%2F2235745%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240704%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240704T074457Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Da4469ce9d278456a9a6c398ca6ed5b17c1c8b0b6107c3bc5c0d7385c7542b2393219a3f1e7f0cd67e6e44b19f167c6da695ed272400237b96a5b8e4de44ed92edad63ec52c259eb901d798828a3ede03450dcc24ccecd6b8892b6d465fe95954d0c952b7afcd0cb632514b1d57377b3331c311bda11542711692a149c7859606ecabfefa13027736e6429842d5d080edf5ee831fb631a7ec7ee656aa1c1203efb0e07049db96b2fbfd69d1f17e1d4654f3bbc96d83bd332110ec2dcee890f658ea55c7d192aa7c8abf832983d1dc2bd7164c68ea13bcaa78252c07cc889c4ed47bd9d7daf9e91998ec114d504a8a6989f4325c70ab6e70158b8f87f31c260203'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "jGSgiP9CtAsD"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2021-05-22T20:16:37.54011Z",
          "iopub.execute_input": "2021-05-22T20:16:37.540435Z",
          "iopub.status.idle": "2021-05-22T20:16:37.881191Z",
          "shell.execute_reply.started": "2021-05-22T20:16:37.540405Z",
          "shell.execute_reply": "2021-05-22T20:16:37.876472Z"
        },
        "trusted": true,
        "id": "lyNsiRZGtAsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# for reading and displaying images\n",
        "from skimage import io, transform\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# for creating validation set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# for evaluating the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "# PyTorch libraries and modules\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T20:16:38.313089Z",
          "iopub.execute_input": "2021-05-22T20:16:38.313412Z",
          "iopub.status.idle": "2021-05-22T20:16:38.325375Z",
          "shell.execute_reply.started": "2021-05-22T20:16:38.313379Z",
          "shell.execute_reply": "2021-05-22T20:16:38.324559Z"
        },
        "trusted": true,
        "id": "ubmJQkBetAsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train.csv data\n",
        "train_data = pd.read_csv(\"/kaggle/input/traincsv/train.csv\")\n",
        "#test = pd.read_csv('/kaggle/input/deep-learning-for-msc-coursework-2021/test')\n",
        "sample_submission = pd.read_csv(\"/kaggle/input/deep-learning-for-msc-coursework-2021/example.csv\")\n",
        "#print(train_data.tail(20))\n",
        "#print(\"length of the dataset \"+ str(len(train_data)))\n",
        "\n",
        "# adding path column to indicate each img address\n",
        "#train_data[\"path\"]=  train_data[\"Id\"].astype(str)\n",
        "#train_data[\"Id\"]= train_data[\"path\"]+\".png\"\n",
        "\n",
        "\n",
        "# data distributions\n",
        "print(train_data['Type'].value_counts())\n",
        "\n",
        "# encode the label data to be represent with numbers (0,1,2,3) insteted of  Immune,Connective, Cancer, Normal\n",
        "train_data['Type'] = pd.factorize(train_data['Type'])[0]\n",
        "\n",
        "train_data['Type'].value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T20:16:38.493569Z",
          "iopub.execute_input": "2021-05-22T20:16:38.493816Z",
          "iopub.status.idle": "2021-05-22T20:16:38.516033Z",
          "shell.execute_reply.started": "2021-05-22T20:16:38.493792Z",
          "shell.execute_reply": "2021-05-22T20:16:38.515305Z"
        },
        "trusted": true,
        "id": "7yKJn8yAtAsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> label encoding </h2>\n",
        "- Connective = 0<br>\n",
        "- Immune = 1<br>\n",
        "- Cancer = 2 <br>\n",
        "- Normal = 3"
      ],
      "metadata": {
        "id": "S6yuR-pVtAsP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " <h4>From the result of this code \"train_data['Type'].value_counts()\" we can see the is imbalance issue amoung data types as shown below:</h4>\n",
        " - Immune   =    729 <br>\n",
        " - Connective  = 726<br>\n",
        " - Cancer     =   546<br>\n",
        " - Normal     =   189<br>\n",
        " <h4> we need to solve this issue before train the classification model to avoid bias results</h4>"
      ],
      "metadata": {
        "id": "ZGDJsC8UtAsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# split into input and output elements\n",
        "X, y = train_data, train_data['Type']\n",
        "strategy = {0:729, 1:729, 2:729, 3:729}\n",
        "y = LabelEncoder().fit_transform(y)\n",
        "oversample = SMOTE(sampling_strategy=strategy)\n",
        "X_over, y_over = oversample.fit_resample(X, y)\n",
        "\n",
        "print((y_over))\n",
        "X_over = X_over['Id']\n",
        "y_ov = pd.DataFrame(y_over)\n",
        "\n",
        "print(y_ov.value_counts())\n",
        "type(X_over)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T20:16:39.227953Z",
          "iopub.execute_input": "2021-05-22T20:16:39.228271Z",
          "iopub.status.idle": "2021-05-22T20:16:39.252718Z",
          "shell.execute_reply.started": "2021-05-22T20:16:39.22824Z",
          "shell.execute_reply": "2021-05-22T20:16:39.251755Z"
        },
        "trusted": true,
        "id": "4JRhwWV_tAsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In this part of code I will use Random Undersampling technique in order to solve imbalancing issue by change\n",
        "# the classes distribution. Random Undersampling, it is mainly used to randomly delete some records from the\n",
        "# majority classes (labels)from the training dataset.\n",
        "# naive resampling, methods because they assume nothing about the data and no heuristics are used.\n",
        "\n",
        "#from collections import Counter\n",
        "#from sklearn.datasets import make_classification\n",
        "#from imblearn.under_sampling import RandomUnderSampler\n",
        "#from sklearn import datasets\n",
        "\n",
        "\n",
        "#from sklearn.preprocessing import LabelEncoder\n",
        "#from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# define dataset\n",
        "#X, y = make_classification(n_classes=4, n_samples=2190, n_informative =4 , weights=[0.70, 0.70, 0.70, 0.70], flip_y=0)\n",
        "\n",
        "# summarize class distribution\n",
        "#print(Counter(y))\n",
        "# define undersample strategy\n",
        "#train_data['Type'].replace({\" Connective\":0, \" Immune\":1 , \" Cancer\":2,  \" Normal\":3}, inplace=True)\n",
        "# split into input and output elements\n",
        "#X, y = train_data, train_data['Type']\n",
        "\n",
        "\n",
        "#strategy = {0:729, 1:729, 2:729, 3:729}\n",
        "#y = LabelEncoder().fit_transform(y)\n",
        "#oversample = SMOTE(sampling_strategy=strategy)\n",
        "#X_over, y_over = oversample.fit_resample(X, y)\n",
        "\n",
        "#strategy = {0:189, 1:189, 2:189, 3:189}\n",
        "#undersample = RandomUnderSampler(sampling_strategy=strategy)\n",
        "# fit and apply the transform\n",
        "#X_over, y_over = undersample.fit_resample(X, y)\n",
        "# summarize class distribution\n",
        "\n",
        "\n",
        "#print(Counter(y_over))\n",
        "#X_over = X_over['Id']\n",
        "#y_ov = pd.DataFrame(y_over)\n",
        "#y_ov.value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T20:16:39.49059Z",
          "iopub.execute_input": "2021-05-22T20:16:39.490891Z",
          "iopub.status.idle": "2021-05-22T20:16:39.495362Z",
          "shell.execute_reply.started": "2021-05-22T20:16:39.490863Z",
          "shell.execute_reply": "2021-05-22T20:16:39.494253Z"
        },
        "trusted": true,
        "id": "xV5GBYL2tAsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading training images\n",
        "import cv2\n",
        "train_img = []\n",
        "for img_name in tqdm(X_over):\n",
        "    # defining the image path\n",
        "    image_path = '/kaggle/input/deep-learning-for-msc-coursework-2021/train/train/' + str(img_name) + '.png'\n",
        "    # reading the image\n",
        "    img = cv2.imread(image_path)\n",
        "    # normalizing the pixel values\n",
        "    #img /= 255.0\n",
        "    # converting the type of pixel to float 32\n",
        "    img = img.astype('float32')\n",
        "    # appending the image into the list\n",
        "    train_img.append(img)\n",
        "\n",
        "# converting the list to numpy array\n",
        "train_x = np.array(train_img)\n",
        "# defining the target\n",
        "train_y =y_over #train_data['Type'].values\n",
        "train_x.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T20:16:39.729809Z",
          "iopub.execute_input": "2021-05-22T20:16:39.730076Z",
          "iopub.status.idle": "2021-05-22T20:16:43.631353Z",
          "shell.execute_reply.started": "2021-05-22T20:16:39.730051Z",
          "shell.execute_reply": "2021-05-22T20:16:43.63034Z"
        },
        "trusted": true,
        "id": "zQFyJ4ZDtAsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing images\n",
        "i = 0\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(221), plt.imshow(train_x[i])\n",
        "plt.subplot(222), plt.imshow(train_x[i+25], cmap='gray')\n",
        "plt.subplot(223), plt.imshow(train_x[i+50], cmap='gray')\n",
        "plt.subplot(224), plt.imshow(train_x[i+75], cmap='gray')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T20:16:43.633229Z",
          "iopub.execute_input": "2021-05-22T20:16:43.633884Z",
          "iopub.status.idle": "2021-05-22T20:16:44.094882Z",
          "shell.execute_reply.started": "2021-05-22T20:16:43.63384Z",
          "shell.execute_reply": "2021-05-22T20:16:44.094096Z"
        },
        "trusted": true,
        "id": "nuo4x9z9tAsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# spiliting the training dataset into 75% train and 25% validation sets\n",
        "\n",
        "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size = 0.25)\n",
        "c1 = train_x.shape[0]\n",
        "c2 = val_x.shape[0]\n",
        "(train_x.shape, train_y.shape), (val_x.shape, val_y.shape)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T20:16:44.096663Z",
          "iopub.execute_input": "2021-05-22T20:16:44.097017Z",
          "iopub.status.idle": "2021-05-22T20:16:44.149335Z",
          "shell.execute_reply.started": "2021-05-22T20:16:44.096975Z",
          "shell.execute_reply": "2021-05-22T20:16:44.148335Z"
        },
        "trusted": true,
        "id": "iyiFMxHCtAsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting training images into torch format\n",
        "train_x = train_x.reshape(c1,3, 64, 64)\n",
        "train_x  = torch.from_numpy(train_x)\n",
        "\n",
        "# converting the target into torch format\n",
        "train_y = train_y.astype(int);\n",
        "train_y = torch.from_numpy(train_y)\n",
        "\n",
        "# shape of training data\n",
        "train_x.shape, train_y.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T20:16:44.151114Z",
          "iopub.execute_input": "2021-05-22T20:16:44.151489Z",
          "iopub.status.idle": "2021-05-22T20:16:44.158383Z",
          "shell.execute_reply.started": "2021-05-22T20:16:44.151435Z",
          "shell.execute_reply": "2021-05-22T20:16:44.157409Z"
        },
        "trusted": true,
        "id": "Jf7patdFtAsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting validation images into torch format\n",
        "val_x = val_x.reshape(c2,3, 64, 64)\n",
        "val_x  = torch.from_numpy(val_x)\n",
        "\n",
        "# converting the target into torch format\n",
        "val_y = val_y.astype(int);\n",
        "val_y = torch.from_numpy(val_y)\n",
        "\n",
        "# shape of validation data\n",
        "val_x.shape, val_y.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T20:16:44.160038Z",
          "iopub.execute_input": "2021-05-22T20:16:44.16041Z",
          "iopub.status.idle": "2021-05-22T20:16:44.170601Z",
          "shell.execute_reply.started": "2021-05-22T20:16:44.160373Z",
          "shell.execute_reply": "2021-05-22T20:16:44.169606Z"
        },
        "trusted": true,
        "id": "4iU7EnDrtAsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.cnn_layers = Sequential(\n",
        "            # Defining a 2D convolution layer\n",
        "            Conv2d(3, 10, kernel_size=3, stride=1, padding=1),\n",
        "            BatchNorm2d(10),\n",
        "            ReLU(inplace=True),\n",
        "            MaxPool2d(kernel_size=2, stride=2),\n",
        "            # Defining another 2D convolution layer\n",
        "            Conv2d(10, 4, kernel_size=3, stride=1, padding=1),\n",
        "            BatchNorm2d(4),\n",
        "            ReLU(inplace=True),\n",
        "            MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "        )\n",
        "\n",
        "        self.linear_layers = Sequential(\n",
        "            Linear(4 * 16 * 16 , 4)\n",
        "        )\n",
        "    # Defining the forward pass\n",
        "    def forward(self, x):\n",
        "        x = self.cnn_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear_layers(x)\n",
        "        return x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T20:16:44.172145Z",
          "iopub.execute_input": "2021-05-22T20:16:44.172564Z",
          "iopub.status.idle": "2021-05-22T20:16:44.181322Z",
          "shell.execute_reply.started": "2021-05-22T20:16:44.172498Z",
          "shell.execute_reply": "2021-05-22T20:16:44.180258Z"
        },
        "trusted": true,
        "id": "jEIIXZbgtAsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the model\n",
        "model = Net()\n",
        "# defining the optimizer\n",
        "optimizer = Adam(model.parameters(), lr=0.07)\n",
        "# defining the loss function\n",
        "criterion = CrossEntropyLoss()\n",
        "# checking if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T20:16:44.182797Z",
          "iopub.execute_input": "2021-05-22T20:16:44.183187Z",
          "iopub.status.idle": "2021-05-22T20:16:44.200195Z",
          "shell.execute_reply.started": "2021-05-22T20:16:44.183152Z",
          "shell.execute_reply": "2021-05-22T20:16:44.199369Z"
        },
        "trusted": true,
        "id": "A4q-MfQHtAsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    tr_loss = 0\n",
        "    # getting the training set\n",
        "    x_train, y_train = Variable(train_x), Variable(train_y)\n",
        "    # getting the validation set\n",
        "    x_val, y_val = Variable(val_x), Variable(val_y)\n",
        "    # converting the data into GPU format\n",
        "    if torch.cuda.is_available():\n",
        "        x_train = x_train.cuda()\n",
        "        y_train = y_train.cuda()\n",
        "        x_val = x_val.cuda()\n",
        "        y_val = y_val.cuda()\n",
        "\n",
        "    # clearing the Gradients of the model parameters\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # prediction for training and validation set\n",
        "    output_train = model(x_train)\n",
        "    output_val = model(x_val)\n",
        "\n",
        "    # computing the training and validation loss\n",
        "    loss_train = criterion(output_train, y_train)\n",
        "    loss_val = criterion(output_val, y_val)\n",
        "    train_losses.append(loss_train)\n",
        "    val_losses.append(loss_val)\n",
        "\n",
        "    # computing the updated weights of all the model parameters\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "    tr_loss = loss_train.item()\n",
        "    if epoch%2 == 0:\n",
        "        # printing the validation loss\n",
        "        print('Epoch : ',epoch+1, '\\t', 'loss :', loss_val)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T20:16:44.203657Z",
          "iopub.execute_input": "2021-05-22T20:16:44.203897Z",
          "iopub.status.idle": "2021-05-22T20:16:44.327137Z",
          "shell.execute_reply.started": "2021-05-22T20:16:44.203868Z",
          "shell.execute_reply": "2021-05-22T20:16:44.326147Z"
        },
        "trusted": true,
        "id": "ugEeI6ROtAsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the number of epochs\n",
        "n_epochs = 33\n",
        "# empty list to store training losses\n",
        "train_losses = []\n",
        "# empty list to store validation losses\n",
        "val_losses = []\n",
        "# training the model\n",
        "for epoch in range(n_epochs):\n",
        "    train(epoch)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T20:16:44.328838Z",
          "iopub.execute_input": "2021-05-22T20:16:44.329211Z",
          "iopub.status.idle": "2021-05-22T20:16:50.087284Z",
          "shell.execute_reply.started": "2021-05-22T20:16:44.329175Z",
          "shell.execute_reply": "2021-05-22T20:16:50.086276Z"
        },
        "trusted": true,
        "id": "zUe0VsrntAsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the training and validation loss\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(val_losses, label='Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T20:16:50.088867Z",
          "iopub.execute_input": "2021-05-22T20:16:50.089231Z",
          "iopub.status.idle": "2021-05-22T20:16:50.229031Z",
          "shell.execute_reply.started": "2021-05-22T20:16:50.089192Z",
          "shell.execute_reply": "2021-05-22T20:16:50.22804Z"
        },
        "trusted": true,
        "id": "FFpc2SJRtAsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction for training set\n",
        "with torch.no_grad():\n",
        "    output = model(train_x.cuda())\n",
        "\n",
        "softmax = torch.exp(output).cpu()\n",
        "prob = list(softmax.numpy())\n",
        "predictions = np.argmax(prob, axis=1)\n",
        "\n",
        "# accuracy on training set\n",
        "accuracy_score(train_y, predictions)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T20:16:50.230382Z",
          "iopub.execute_input": "2021-05-22T20:16:50.230747Z",
          "iopub.status.idle": "2021-05-22T20:16:50.290538Z",
          "shell.execute_reply.started": "2021-05-22T20:16:50.230711Z",
          "shell.execute_reply": "2021-05-22T20:16:50.289618Z"
        },
        "trusted": true,
        "id": "NyYVzZBWtAsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction for validation set\n",
        "with torch.no_grad():\n",
        "    output = model(val_x.cuda())\n",
        "\n",
        "softmax = torch.exp(output).cpu()\n",
        "prob = list(softmax.numpy())\n",
        "predictions = np.argmax(prob, axis=1)\n",
        "\n",
        "# accuracy on validation set\n",
        "accuracy_score(val_y, predictions)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T20:16:50.291773Z",
          "iopub.execute_input": "2021-05-22T20:16:50.292156Z",
          "iopub.status.idle": "2021-05-22T20:16:50.317128Z",
          "shell.execute_reply.started": "2021-05-22T20:16:50.292122Z",
          "shell.execute_reply": "2021-05-22T20:16:50.316227Z"
        },
        "trusted": true,
        "id": "H3Z9eZD1tAsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading test images\n",
        "test_img = []\n",
        "\n",
        "for img_name in tqdm(sample_submission['Id']):\n",
        "    # defining the image path\n",
        "    image_path = '/kaggle/input/deep-learning-for-msc-coursework-2021/test/test/' + str(img_name) + '.png'\n",
        "    # reading the image\n",
        "    img = cv2.imread(image_path)\n",
        "    # normalizing the pixel values\n",
        "    #img /= 255.0\n",
        "    # converting the type of pixel to float 32\n",
        "    img = img.astype('float32')\n",
        "    # appending the image into the list\n",
        "    test_img.append(img)\n",
        "\n",
        "# converting the list to numpy array\n",
        "test_x = np.array(test_img)\n",
        "\n",
        "test_x.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T20:16:50.318267Z",
          "iopub.execute_input": "2021-05-22T20:16:50.31862Z",
          "iopub.status.idle": "2021-05-22T20:16:50.80199Z",
          "shell.execute_reply.started": "2021-05-22T20:16:50.318585Z",
          "shell.execute_reply": "2021-05-22T20:16:50.801221Z"
        },
        "trusted": true,
        "id": "B5O7SIy1tAsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting training images into torch format\n",
        "test_x = test_x.reshape(400,3, 64, 64)\n",
        "test_x  = torch.from_numpy(test_x)\n",
        "test_x.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T20:16:50.804607Z",
          "iopub.execute_input": "2021-05-22T20:16:50.804847Z",
          "iopub.status.idle": "2021-05-22T20:16:50.813742Z",
          "shell.execute_reply.started": "2021-05-22T20:16:50.804822Z",
          "shell.execute_reply": "2021-05-22T20:16:50.812822Z"
        },
        "trusted": true,
        "id": "PBu5FIhEtAsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generating predictions for test set\n",
        "with torch.no_grad():\n",
        "    output = model(test_x.cuda())\n",
        "\n",
        "softmax = torch.exp(output).cpu()\n",
        "prob = list(softmax.numpy())\n",
        "predictions = np.argmax(prob, axis=1)\n",
        "\n",
        "# replacing the label with prediction\n",
        "sample_submission['Type'] = predictions\n",
        "sample_submission['Type'].replace({0 : \"Connective\", 1: \"Immune\", 2: \"Cancer\", 3: \"Normal\"}, inplace=True)\n",
        "print(sample_submission.tail(60))\n",
        "sample_submission['Type'].value_counts()\n",
        "predictions"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T20:16:50.81689Z",
          "iopub.execute_input": "2021-05-22T20:16:50.817132Z",
          "iopub.status.idle": "2021-05-22T20:16:50.845422Z",
          "shell.execute_reply.started": "2021-05-22T20:16:50.81711Z",
          "shell.execute_reply": "2021-05-22T20:16:50.844725Z"
        },
        "trusted": true,
        "id": "GbxSfFTBtAsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the file\n",
        "sample_submission.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T20:16:50.847814Z",
          "iopub.execute_input": "2021-05-22T20:16:50.848058Z",
          "iopub.status.idle": "2021-05-22T20:16:51.068539Z",
          "shell.execute_reply.started": "2021-05-22T20:16:50.848034Z",
          "shell.execute_reply": "2021-05-22T20:16:51.067619Z"
        },
        "trusted": true,
        "id": "MJ565kdRtAsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# spiliting the training dataset into train and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, valid_data = train_test_split(train_data, stratify=train_data[\"Type\"], test_size=0.2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T20:16:51.06989Z",
          "iopub.execute_input": "2021-05-22T20:16:51.070229Z",
          "iopub.status.idle": "2021-05-22T20:16:51.079767Z",
          "shell.execute_reply.started": "2021-05-22T20:16:51.070192Z",
          "shell.execute_reply": "2021-05-22T20:16:51.078823Z"
        },
        "trusted": true,
        "id": "551tHbWmtAsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode the label data to be represent with numbers (0,1,2,3) insteted of  Immune,Connective, Cancer, Normal\n",
        "train_data['Type'] = pd.factorize(train_data['Type'])[0]\n",
        "train_data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T20:16:51.081226Z",
          "iopub.execute_input": "2021-05-22T20:16:51.081632Z",
          "iopub.status.idle": "2021-05-22T20:16:51.096197Z",
          "shell.execute_reply.started": "2021-05-22T20:16:51.081593Z",
          "shell.execute_reply": "2021-05-22T20:16:51.095088Z"
        },
        "trusted": true,
        "id": "z5jyjU-StAsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data distributions\n",
        "train_data['Type'].value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T20:16:51.097712Z",
          "iopub.execute_input": "2021-05-22T20:16:51.098146Z",
          "iopub.status.idle": "2021-05-22T20:16:51.106041Z",
          "shell.execute_reply.started": "2021-05-22T20:16:51.09811Z",
          "shell.execute_reply": "2021-05-22T20:16:51.105168Z"
        },
        "trusted": true,
        "id": "KPGl4vcxtAsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating tensor from train_data\n",
        "#import torch\n",
        "targets = torch.tensor(train_data['Type'].values)\n",
        "targets\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T20:16:51.1082Z",
          "iopub.execute_input": "2021-05-22T20:16:51.108444Z",
          "iopub.status.idle": "2021-05-22T20:16:51.117048Z",
          "shell.execute_reply.started": "2021-05-22T20:16:51.108413Z",
          "shell.execute_reply": "2021-05-22T20:16:51.116177Z"
        },
        "trusted": true,
        "id": "m3zBRpQbtAsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using the ImageFolder class from torchvision to load the data as PyTorch tensors\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "trainImage_dataset = ImageFolder('/kaggle/input/deep-learning-for-msc-coursework-2021/train',transform=ToTensor())\n",
        "print(len(trainImage_dataset))\n",
        "trainImage_dataset[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T20:16:51.11852Z",
          "iopub.execute_input": "2021-05-22T20:16:51.118919Z",
          "iopub.status.idle": "2021-05-22T20:16:51.147125Z",
          "shell.execute_reply.started": "2021-05-22T20:16:51.118882Z",
          "shell.execute_reply": "2021-05-22T20:16:51.14644Z"
        },
        "trusted": true,
        "id": "ej4popY2tAsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "QzdWZbQVtAsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "H3Ey9n0HtAse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pf0O4QSStAse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K2CK2XTBtAse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zYVAR_jRtAsf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}